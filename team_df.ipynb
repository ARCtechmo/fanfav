{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120c884-58e9-4c69-bdc7-7d5139d977f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This produces the dataframe for NFL Team Defesne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd344e-6edc-4d54-a85f-1b117245fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6dcf0-04fe-472a-9a00-e8a7152819e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required installations\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119c32d-3dff-4e61-a9bb-23cb1d0c6b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c869bb49-671e-449d-8f50-7497b090cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REQUIRED ACTIONS - Include in a README doc ## \n",
    "# modify the season start date in the 'get_current_week' function\n",
    "# modify the number of weeks if the NFL adds regular season games to the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75fdcba-8369-4c5c-bcbd-6786ac3c6c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451c6d33-7366-4724-a6ef-f639b8f597cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36166f1-9988-4fb3-b812-7ba768281837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2710d66f-5327-48b8-b651-0f2b396bd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas options to display all columns in a single row without wrapping\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5d8ba-cbb8-4e0d-8bcd-3a441c569d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ee9cc1-242b-4d1a-89fb-0087a0fe2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the current week of the NFL season\n",
    "def get_current_week():\n",
    "    current_date = datetime.now()\n",
    "    season_start_date = datetime(2024, 9, 4)  # Update for the season start\n",
    "    current_week = ((current_date - season_start_date).days // 7) + 1\n",
    "    return current_week\n",
    "\n",
    "# Define the current NFL year, week, and season type\n",
    "current_year = datetime.now().year\n",
    "current_week = get_current_week()\n",
    "seasontype = 2 if current_week <= 18 else 3  # Regular season or playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c510def-7655-4294-8f68-792f936a143b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce77a26-0d86-42d0-9b75-9b11c809d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the years to pull\n",
    "# nfl.import_weekly_data(years, columns, downcast)\n",
    "def get_year_range(current_year, current_week, start_year=2017):\n",
    "    if current_week <= 18:  # Regular season\n",
    "        return list(range(start_year, current_year + 1))\n",
    "    else:  # Playoffs\n",
    "        return list(range(start_year, current_year))\n",
    "\n",
    "# Use the function\n",
    "years = get_year_range(current_year, current_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31721960-1f58-45fc-a41f-464e0335987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b120c571-ed7d-482b-91f6-56bc8dcb461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_team_boxscore(filepath):\n",
    "    # Step 1: Read skipping the first header row\n",
    "    df = pd.read_excel(filepath, skiprows=1)\n",
    "\n",
    "    # Step 2: Clean columns\n",
    "    def normalize_col(col):\n",
    "        return (\n",
    "            str(col).replace('\\n', ' ')\n",
    "                    .replace('(', '')\n",
    "                    .replace(')', '')\n",
    "                    .replace('\"', '')\n",
    "                    .replace('#', '')\n",
    "                    .replace('$', '')\n",
    "                    .replace('/', '')\n",
    "                    .replace('-', ' ')\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                    .replace('  ', ' ')\n",
    "        )\n",
    "    \n",
    "    cleaned_cols = [normalize_col(col) for col in df.columns]\n",
    "    df.columns = cleaned_cols\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98885427-0d8a-4d75-9949-b0d4cf0f2774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ac61e4e-3369-42ec-a79b-cbcbb496d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing team file: 2017-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2017_df.xlsx | Shape: (534, 64)\n",
      "ðŸ“‚ Processing team file: 2018-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2018_df.xlsx | Shape: (534, 65)\n",
      "ðŸ“‚ Processing team file: 2019-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2019_df.xlsx | Shape: (534, 64)\n",
      "ðŸ“‚ Processing team file: 2020-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2020_df.xlsx | Shape: (538, 64)\n",
      "ðŸ“‚ Processing team file: 2021-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2021_df.xlsx | Shape: (570, 64)\n",
      "ðŸ“‚ Processing team file: 2022-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2022_df.xlsx | Shape: (568, 65)\n",
      "ðŸ“‚ Processing team file: 2023-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2023_df.xlsx | Shape: (570, 65)\n",
      "ðŸ“‚ Processing team file: 2024-NFL_Box_Score_Team-Stats.xlsx\n",
      "âœ… Saved: team_stats_2024_df.xlsx | Shape: (570, 65)\n"
     ]
    }
   ],
   "source": [
    "# Team name to abbreviation map (same as before)\n",
    "team_abbr_map = {\n",
    "    'Arizona Cardinals': 'ARI', 'Atlanta Falcons': 'ATL', 'Baltimore Ravens': 'BAL',\n",
    "    'Buffalo Bills': 'BUF', 'Carolina Panthers': 'CAR', 'Chicago Bears': 'CHI',\n",
    "    'Cincinnati Bengals': 'CIN', 'Cleveland Browns': 'CLE', 'Dallas Cowboys': 'DAL',\n",
    "    'Denver Broncos': 'DEN', 'Detroit Lions': 'DET', 'Green Bay Packers': 'GB',\n",
    "    'Houston Texans': 'HOU', 'Indianapolis Colts': 'IND', 'Jacksonville Jaguars': 'JAX',\n",
    "    'Kansas City Chiefs': 'KC', 'Las Vegas Raiders': 'LV', 'Los Angeles Chargers': 'LAC',\n",
    "    'Los Angeles Rams': 'LAR', 'Miami Dolphins': 'MIA', 'Minnesota Vikings': 'MIN',\n",
    "    'New England Patriots': 'NE', 'New Orleans Saints': 'NO', 'New York Giants': 'NYG',\n",
    "    'New York Jets': 'NYJ', 'Philadelphia Eagles': 'PHI', 'Pittsburgh Steelers': 'PIT',\n",
    "    'San Francisco 49ers': 'SF', 'Seattle Seahawks': 'SEA', 'Tampa Bay Buccaneers': 'TB',\n",
    "    'Tennessee Titans': 'TEN', 'Washington Commanders': 'WAS',\n",
    "    \n",
    "    # Legacy names\n",
    "    'Oakland Raiders': 'LV', 'Washington Redskins': 'WAS', 'Washington Football Team': 'WAS'\n",
    "}\n",
    "\n",
    "# Storage\n",
    "team_yearly_dfs = {}\n",
    "team_yearly_files = []\n",
    "\n",
    "for year in years:\n",
    "    team_file = f\"{year}-NFL_Box_Score_Team-Stats.xlsx\"\n",
    "    try:\n",
    "        print(f\"ðŸ“‚ Processing team file: {team_file}\")\n",
    "        df = clean_team_boxscore(team_file)\n",
    "\n",
    "        # Add 'season' column from year\n",
    "        df['season'] = year\n",
    "\n",
    "        # Map team abbreviation\n",
    "        df['team_abbr'] = df['team'].map(team_abbr_map)\n",
    "\n",
    "        # Save to dictionary\n",
    "        team_yearly_dfs[year] = df\n",
    "\n",
    "        # Optional: save for inspection\n",
    "        file_name = f\"team_stats_{year}_df.xlsx\"\n",
    "        df.to_excel(file_name, index=False)\n",
    "        team_yearly_files.append(file_name)\n",
    "        print(f\"âœ… Saved: {file_name} | Shape: {df.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54be633-570d-49fb-a01c-7de5e4e37515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09f0aeed-639d-469b-a3b5-4cbadda260bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“… Validating 2017...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2018...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2019...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2020...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2021...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2022...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2023...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n",
      "\n",
      "ðŸ“… Validating 2024...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game id/team_abbr rows.\n",
      "âœ… All game ids have exactly 2 teams.\n",
      "â„¹ï¸ Nulls in core fields: 0\n"
     ]
    }
   ],
   "source": [
    "for year, df in team_yearly_dfs.items():\n",
    "    print(f\"\\nðŸ“… Validating {year}...\")\n",
    "\n",
    "    # 1. Missing team_abbr\n",
    "    missing_abbr = df['team_abbr'].isna().sum()\n",
    "    if missing_abbr == 0:\n",
    "        print(\"âœ… All team_abbr values present.\")\n",
    "    else:\n",
    "        print(f\"âŒ Missing team_abbr: {missing_abbr}\")\n",
    "\n",
    "    # 2. Duplicates per season+week+game_id+team_abbr\n",
    "    dup_keys = ['season', 'week', 'game id', 'team_abbr']\n",
    "    duplicates = df.duplicated(subset=dup_keys).sum()\n",
    "    if duplicates == 0:\n",
    "        print(\"âœ… No duplicate season/week/game id/team_abbr rows.\")\n",
    "    else:\n",
    "        print(f\"âŒ Duplicate rows found: {duplicates}\")\n",
    "\n",
    "    # 3. Unique game_id should have exactly 2 teams\n",
    "    game_counts = df['game id'].value_counts()\n",
    "    bad_games = game_counts[game_counts != 2]\n",
    "    if len(bad_games) == 0:\n",
    "        print(\"âœ… All game ids have exactly 2 teams.\")\n",
    "    else:\n",
    "        print(f\"âŒ {len(bad_games)} game_ids do not have 2 teams.\")\n",
    "\n",
    "    # 4. Optional: Nulls in core fields\n",
    "    core_nulls = df[['season', 'week', 'team', 'team_abbr']].isna().sum().sum()\n",
    "    print(f\"â„¹ï¸ Nulls in core fields: {core_nulls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1cb2d-515f-4873-a9e9-d4bd23000ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23f07c1f-c099-4e5a-95cb-08fd46a7270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined shape: (4418, 68)\n",
      "ðŸ’¾ Saved: team_stats_2017_2024_df.xlsx\n"
     ]
    }
   ],
   "source": [
    "team_stats_combined_df = pd.concat(team_yearly_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Optional: Save\n",
    "start_year, end_year = min(years), max(years)\n",
    "combined_filename = f\"team_stats_{start_year}_{end_year}_df.xlsx\"\n",
    "team_stats_combined_df.to_excel(combined_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Combined shape: {team_stats_combined_df.shape}\")\n",
    "print(f\"ðŸ’¾ Saved: {combined_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac42cc9-dc50-4d26-981c-f12a6a6cb2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0de46d-bcaa-48ac-bc87-d41e6f1def59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_dfs(col):\n",
    "    \"\"\"\n",
    "    Cleans and flattens multi-index column names for DFS salary Excel files:\n",
    "    - Joins tuples if multi-index\n",
    "    - Removes special characters\n",
    "    - Normalizes spaces\n",
    "    - Converts to lowercase for matching\n",
    "    \"\"\"\n",
    "    if isinstance(col, tuple):\n",
    "        col = ' '.join(str(x) for x in col if x)\n",
    "\n",
    "    return (\n",
    "        str(col)\n",
    "        .replace('\\n', ' ')\n",
    "        .replace('(', '')\n",
    "        .replace(')', '')\n",
    "        .replace('\"', '')\n",
    "        .replace('#', '')\n",
    "        .replace('$', '')\n",
    "        .replace('/', '')\n",
    "        .replace('-', ' ')\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace('  ', ' ')\n",
    "        .replace('   ', ' ')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cea16-fe80-4e81-be95-29dbcca4020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9316021c-3734-49e2-82e9-3a005dcfcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs_salary_file(filepath, year):\n",
    "    # Load raw DFS file\n",
    "    raw = pd.read_excel(filepath, header=[0, 1])\n",
    "    raw.columns = [clean_column_dfs(col) for col in raw.columns]\n",
    "\n",
    "    # Filter to defenses: DK uses 'dst'; FD uses 'dst' or 'd'\n",
    "    raw_filtered = raw[\n",
    "        raw['position draftkings'].str.lower().isin(['dst']) |\n",
    "        raw['position fanduel'].str.lower().isin(['dst', 'd'])\n",
    "    ].copy()\n",
    "\n",
    "    # Fuzzy mapping logic\n",
    "    col_map = {}\n",
    "    for col in raw_filtered.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'game id' in col_lower:\n",
    "            col_map['game_id'] = col\n",
    "        elif 'player id' in col_lower:\n",
    "            col_map['player_id'] = col\n",
    "        elif 'week' in col_lower:\n",
    "            col_map['week'] = col\n",
    "        elif 'team' in col_lower and 'information' in col_lower:\n",
    "            col_map['team'] = col\n",
    "        elif 'salary' in col_lower and 'draftkings' in col_lower:\n",
    "            col_map['dk_salary'] = col\n",
    "        elif 'salary' in col_lower and 'fanduel' in col_lower:\n",
    "            col_map['fd_salary'] = col\n",
    "        elif 'fantasy points' in col_lower and 'draftkings' in col_lower:\n",
    "            col_map['dk_points'] = col\n",
    "        elif 'fantasy points' in col_lower and 'fanduel' in col_lower:\n",
    "            col_map['fd_points'] = col\n",
    "\n",
    "    # Required columns\n",
    "    required = ['game_id', 'player_id', 'week', 'team', 'dk_salary', 'fd_salary', 'dk_points', 'fd_points']\n",
    "    missing = [k for k in required if k not in col_map]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "    # Subset and rename\n",
    "    df = raw_filtered[[col_map[k] for k in required]].copy()\n",
    "    df.columns = required\n",
    "\n",
    "    # Add season column\n",
    "    df['season'] = int(year)\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df['week'] = pd.to_numeric(df['week'], errors='coerce')\n",
    "    for col in ['dk_salary', 'fd_salary', 'dk_points', 'fd_points']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Use player_id as team_abbr (works for D/ST)\n",
    "    df['team_abbr'] = df['player_id']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46106c4d-239d-4d7e-b9a5-ce3b9d0d884f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8bf480a-4583-4fd3-93c7-a1e48144e1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’µ Processing DFS salary file for 2017\n",
      "âœ… Saved: team_dfs_2017_df.xlsx | Shape: (532, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2018\n",
      "âœ… Saved: team_dfs_2018_df.xlsx | Shape: (532, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2019\n",
      "âœ… Saved: team_dfs_2019_df.xlsx | Shape: (532, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2020\n",
      "âœ… Saved: team_dfs_2020_df.xlsx | Shape: (532, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2021\n",
      "âœ… Saved: team_dfs_2021_df.xlsx | Shape: (564, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2022\n",
      "âœ… Saved: team_dfs_2022_df.xlsx | Shape: (566, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2023\n",
      "âœ… Saved: team_dfs_2023_df.xlsx | Shape: (568, 10)\n",
      "\n",
      "ðŸ’µ Processing DFS salary file for 2024\n",
      "âœ… Saved: team_dfs_2024_df.xlsx | Shape: (567, 10)\n"
     ]
    }
   ],
   "source": [
    "dfs_salary_dfs = {}\n",
    "\n",
    "for year in years:\n",
    "    dfs_file = f\"NFL-{year}-DFS-Dataset.xlsx\"\n",
    "    try:\n",
    "        print(f\"\\nðŸ’µ Processing DFS salary file for {year}\")\n",
    "        \n",
    "        # Process and store\n",
    "        df_dfs = process_dfs_salary_file(dfs_file, year)\n",
    "        dfs_salary_dfs[year] = df_dfs\n",
    "\n",
    "        # Save to Excel\n",
    "        output_file = f\"team_dfs_{year}_df.xlsx\"\n",
    "        df_dfs.to_excel(output_file, index=False)\n",
    "        print(f\"âœ… Saved: {output_file} | Shape: {df_dfs.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58f502-c7c2-4279-8d6c-ae74f509eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "817f810a-1436-4f2c-ae37-f7306a16d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“… Validating DFS data for 2017...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 6\n",
      "\n",
      "ðŸ“… Validating DFS data for 2018...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 2\n",
      "\n",
      "ðŸ“… Validating DFS data for 2019...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 0\n",
      "\n",
      "ðŸ“… Validating DFS data for 2020...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 0\n",
      "\n",
      "ðŸ“… Validating DFS data for 2021...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 113\n",
      "\n",
      "ðŸ“… Validating DFS data for 2022...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 2\n",
      "\n",
      "ðŸ“… Validating DFS data for 2023...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 0\n",
      "\n",
      "ðŸ“… Validating DFS data for 2024...\n",
      "âœ… All team_abbr values present.\n",
      "âœ… No duplicate season/week/game_id/team_abbr rows.\n",
      "â„¹ï¸ Null salary cells: 0\n",
      "\n",
      "âœ… Final combined DFS salary shape: (4393, 10)\n",
      "ðŸ’¾ Saved: team_dfs_2017_2024_df.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Validate\n",
    "for year, df in dfs_salary_dfs.items():\n",
    "    print(f\"\\nðŸ“… Validating DFS data for {year}...\")\n",
    "\n",
    "    # Check core fields\n",
    "    core_fields = ['season', 'week', 'game_id', 'team_abbr']\n",
    "    missing_cols = [col for col in core_fields if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"âŒ Missing columns: {missing_cols}\")\n",
    "        continue\n",
    "\n",
    "    # Team_abbr\n",
    "    missing_abbr = df['team_abbr'].isna().sum()\n",
    "    if missing_abbr == 0:\n",
    "        print(\"âœ… All team_abbr values present.\")\n",
    "    else:\n",
    "        print(f\"âŒ Missing team_abbr entries: {missing_abbr}\")\n",
    "\n",
    "    # Duplicate check\n",
    "    dup_rows = df.duplicated(subset=core_fields).sum()\n",
    "    if dup_rows == 0:\n",
    "        print(\"âœ… No duplicate season/week/game_id/team_abbr rows.\")\n",
    "    else:\n",
    "        print(f\"âŒ Duplicate key rows: {dup_rows}\")\n",
    "\n",
    "    # Nulls in salary\n",
    "    nulls = df[['dk_salary', 'fd_salary']].isna().sum().sum()\n",
    "    print(f\"â„¹ï¸ Null salary cells: {nulls}\")\n",
    "\n",
    "# Step 2: Merge\n",
    "team_dfs_combined_df = pd.concat(dfs_salary_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Save combined\n",
    "dfs_combined_filename = f\"team_dfs_{min(years)}_{max(years)}_df.xlsx\"\n",
    "team_dfs_combined_df.to_excel(dfs_combined_filename, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Final combined DFS salary shape: {team_dfs_combined_df.shape}\")\n",
    "print(f\"ðŸ’¾ Saved: {dfs_combined_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdf410-b341-4a37-b366-1aa14338e778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816efdbb-2502-4b9f-a487-30c249760ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using in-memory team_stats_combined_df\n",
      "âœ… Using in-memory team_dfs_combined_df\n",
      "\n",
      "âœ… Merged shape: (4418, 74)\n",
      "â„¹ï¸ Total salary nulls: 719\n",
      "ðŸ’¾ Saved: team_stats_dfs_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Use in-memory dataframes if available\n",
    "if 'team_stats_combined_df' not in locals():\n",
    "    team_stats_combined_df = pd.read_excel(f\"team_stats_{min(years)}_{max(years)}_df.xlsx\")\n",
    "    print(\"ðŸ“‚ Loaded team stats from Excel.\")\n",
    "else:\n",
    "    print(\"âœ… Using in-memory team_stats_combined_df\")\n",
    "\n",
    "if 'team_dfs_combined_df' not in locals():\n",
    "    team_dfs_combined_df = pd.read_excel(f\"team_dfs_{min(years)}_{max(years)}_df.xlsx\")\n",
    "    print(\"ðŸ“‚ Loaded DFS salary from Excel.\")\n",
    "else:\n",
    "    print(\"âœ… Using in-memory team_dfs_combined_df\")\n",
    "\n",
    "# ðŸ›  Normalize key column if needed\n",
    "if 'game id' in team_stats_combined_df.columns:\n",
    "    team_stats_combined_df.rename(columns={'game id': 'game_id'}, inplace=True)\n",
    "\n",
    "# ðŸ” Drop stale salary/point columns if they exist\n",
    "for col in ['dk_salary', 'fd_salary', 'dk_points', 'fd_points']:\n",
    "    if col in team_stats_combined_df.columns:\n",
    "        team_stats_combined_df.drop(columns=col, inplace=True)\n",
    "\n",
    "# ðŸ”— Merge on 4 keys\n",
    "team_stats_dfs_merged_df = team_stats_combined_df.merge(\n",
    "    team_dfs_combined_df,\n",
    "    how='left',\n",
    "    on=['season', 'week', 'game_id', 'team_abbr']\n",
    ")\n",
    "\n",
    "# âœ… Final validation\n",
    "print(f\"\\nâœ… Merged shape: {team_stats_dfs_merged_df.shape}\")\n",
    "salary_nulls = team_stats_dfs_merged_df[['dk_salary', 'fd_salary']].isna().sum().sum()\n",
    "print(f\"â„¹ï¸ Total salary nulls: {salary_nulls}\")\n",
    "\n",
    "# ðŸ’¾ Save to Excel\n",
    "final_merged_filename = f\"team_stats_dfs_{min(years)}_{max(years)}_df.csv\"\n",
    "team_stats_dfs_merged_df.to_csv(final_merged_filename, index=False)\n",
    "print(f\"ðŸ’¾ Saved: {final_merged_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8553c-4fa7-403e-97c0-071685b5f4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "429f4472-067b-4b9b-8010-f43604a1a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_rename_map = {\n",
    "    '1_opp': 'opp_pts_q1',\n",
    "    '2_opp': 'opp_pts_q2',\n",
    "    '3_opp': 'opp_pts_q3',\n",
    "    '4_opp': 'opp_pts_q4',\n",
    "    'rush_opp': 'opp_rush_att',\n",
    "    'yds_opp': 'opp_rush_yds',\n",
    "    'td_opp': 'opp_rush_tds',\n",
    "    'comp_opp': 'opp_pass_comp',\n",
    "    'att_opp': 'opp_pass_att',\n",
    "    'yds.1_opp': 'opp_pass_yds',\n",
    "    'td.1_opp': 'opp_pass_tds',\n",
    "    'total yards_opp': 'opp_total_yards',\n",
    "    'total plays_opp': 'opp_total_plays',\n",
    "    'time of possession_opp': 'opp_time_of_possession',\n",
    "    'third downs made_opp': 'opp_third_downs_made',\n",
    "    'third downs attempted_opp': 'opp_third_downs_attempts',\n",
    "    'fourth downs made_opp': 'opp_fourth_downs_made',\n",
    "    'fourth downs attempted_opp': 'opp_fourth_downs_attempts',\n",
    "    'sacks_opp': 'opp_sacks',\n",
    "    'interceptions made_opp': 'opp_interceptions'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74637ffd-2db8-490d-8f63-ecb67b7555fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afe86f73-6201-4481-817a-74c8c1de9c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final shape with opponent features: (4418, 94)\n",
      "ðŸ’¾ Saved as: team_stats_dfs_merged_features_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Self-merge on game context\n",
    "df_merged = team_stats_dfs_merged_df.merge(\n",
    "    team_stats_dfs_merged_df,\n",
    "    how='inner',\n",
    "    on=['season', 'week', 'game_id'],\n",
    "    suffixes=('', '_opp')\n",
    ")\n",
    "\n",
    "# Filter out self-matches\n",
    "df_merged = df_merged[df_merged['team_abbr'] != df_merged['team_abbr_opp']]\n",
    "\n",
    "\n",
    "# Extract and rename\n",
    "df_opp_features = df_merged[list(opp_rename_map.keys())].rename(columns=opp_rename_map)\n",
    "\n",
    "# Combine with original\n",
    "team_stats_dfs_merged_features_df = pd.concat(\n",
    "    [team_stats_dfs_merged_df.reset_index(drop=True), df_opp_features.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# *** csv file ***\n",
    "team_stats_dfs_merged_features_df.to_csv(\"team_stats_dfs_merged_features_df.csv\", index=False)\n",
    "print(f\"âœ… Final shape with opponent features: {team_stats_dfs_merged_features_df.shape}\")\n",
    "print(\"ðŸ’¾ Saved as: team_stats_dfs_merged_features_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff16943-c3c7-4978-bb4a-765c691f2f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad2ce6a8-900a-4a1b-9da4-db55cde68550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned & finalized dataframe shape: (4418, 87)\n",
      "ðŸ’¾ Saved as: team_stats_dfs_2017_2024_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Lowercase map of current columns\n",
    "col_map = {col.lower().strip(): col for col in team_stats_dfs_merged_features_df.columns}\n",
    "\n",
    "# Step 2: Define your intended canonical column names (lowercase)\n",
    "base_keys = ['season', 'week', 'date', 'game_id', 'team', 'team_abbr', 'venue',\n",
    "             'dk_salary', 'fd_salary', 'dk_points', 'fd_points']\n",
    "\n",
    "defense_keys = ['sacks', 'opponent fumbles recovered', 'defensive fumble recovery td',\n",
    "                'interception return td', 'blocked punt/fg return td', 'safeties',\n",
    "                'blocked kick/punt', 'interceptions made', 'points_allowed']\n",
    "\n",
    "odds_keys = ['opening_odds', 'opening_spread', 'opening_total',\n",
    "             'line_move1', 'line_move2', 'line_move3',\n",
    "             'closing_odds', 'closing_spread', 'closing_total',\n",
    "             'opening_ml', 'closing_ml']\n",
    "\n",
    "# Step 3: Resolve real column names from the map\n",
    "def resolve_keys(keys):\n",
    "    return [col_map[k] for k in keys if k in col_map]\n",
    "\n",
    "base_cols = resolve_keys([k.lower() for k in base_keys])\n",
    "defensive_cols = resolve_keys([k.lower() for k in defense_keys])\n",
    "odds_cols = resolve_keys([k.lower() for k in odds_keys])\n",
    "opp_cols = [col for col in team_stats_dfs_merged_features_df.columns if col.startswith('opp_')]\n",
    "\n",
    "# Step 4: Reorder columns safely\n",
    "final_order = base_cols + defensive_cols + opp_cols + odds_cols\n",
    "remaining_cols = [col for col in team_stats_dfs_merged_features_df.columns if col not in final_order]\n",
    "\n",
    "team_stats_dfs_merged_features_df = team_stats_dfs_merged_features_df[final_order + remaining_cols]\n",
    "\n",
    "# Step 5: Drop raw quarters and leftover noise\n",
    "drop_cols = [col for col in team_stats_dfs_merged_features_df.columns if re.fullmatch(r'[1-4]|OT', col)]\n",
    "drop_cols += ['unnamed: 62', 'opening moneyline', 'closing moneyline', 'start time (et)']\n",
    "\n",
    "team_stats_dfs_merged_features_df = team_stats_dfs_merged_features_df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Step 6: Save final\n",
    "start_year = years[0]\n",
    "end_year = years[-1]\n",
    "final_filename = f\"team_stats_dfs_{start_year}_{end_year}_df.csv\"\n",
    "team_stats_dfs_merged_features_df.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Cleaned & finalized dataframe shape: {team_stats_dfs_merged_features_df.shape}\")\n",
    "print(f\"ðŸ’¾ Saved as: {final_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c3c0c-bc41-40ee-8639-2e6d45cb00f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4166ca-a8b8-436f-bd75-98d6e6d9795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tasks\n",
    "# 1. Restore Scoring Per Quarter Columns\n",
    "# 2. Drop Extra Columns\n",
    "# 3. Reorder Columns\n",
    "# 4. Save Final Team DataFrame\n",
    "# 5. Create Defensive-Only DataFrame\n",
    "# 6. Prevous blocks used \"to_xlsx\" - change to \"to_csv\"\n",
    "# 7. change the filename to team_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1426cef-a91e-4f77-ad13-bed5ea42134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffe540-9bd6-40f3-a85c-8c5a3d36e68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
